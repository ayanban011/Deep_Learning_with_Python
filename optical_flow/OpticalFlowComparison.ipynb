{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"emNA43SRAwTo"},"source":["<table width=100%>\n","<tr>\n","<td width=100%>\n","<h1><b>Master in Computer Vision - M6</b></h1>\n","<h2><b>Dense optical flow comparison</b></h2>\n","<h4>Ayan Banerjee under supervision of Josep Ramon Morros\n","<br>\n","<a href=\"https://imatge.upc.edu/web/\"> GPI @ IDEAI</a> Research group\n","</h4>\n","</td>\n","</tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"5rLrh619MO2h"},"source":["# Dense optical flow computation\n","\n","Compute optical flow with several methods to compare the results. To run this demo:\n","\n"," - First, change runtime type (Runtime --> Change runtime type) to use a GPU.\n","\n"," - Then download the file of_comp.zip that you will find at the virtual campus and upload it here using the menu on the left (click the folder icon, upload the file). **Wait until the upload is complete, it may take a long time**"]},{"cell_type":"markdown","metadata":{"id":"XYCKephUMJz-"},"source":["Install necessary packages\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIh3NVVxAdya","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install recordclass\n","!pip install pyoptflow # Horn-Schunck implementation\n","!pip install flow_vis  # Install package for optical flow visualization using color coding\n","!pip install apng      # To create animated png's"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdXHY3jS7KID","vscode":{"languageId":"python"}},"outputs":[],"source":["!git clone https://github.com/MaximKuklin/RAFT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FOVcKsEtaZ2U","vscode":{"languageId":"python"}},"outputs":[],"source":["# Clone pyflow repository. For Brox method\n","!git clone https://github.com/pathak22/pyflow.git\n","# Build the package\n","%cd /content/pyflow/\n","!python setup.py build_ext -i\n","%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9UdOhDFTAzx","vscode":{"languageId":"python"}},"outputs":[],"source":["!unzip of_comp.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jm7J_vIY7wc1","vscode":{"languageId":"python"}},"outputs":[],"source":["import os\n","import sys\n","import time\n","\n","from argparse import ArgumentParser\n","from collections import OrderedDict\n","\n","import cv2\n","import numpy as np\n","import torch\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","\n","from flow_vis import flow_to_color\n","\n","from pyoptflow import HornSchunck"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGU38VXOb_RY","vscode":{"languageId":"python"}},"outputs":[],"source":["from of_comp.code.display_images import display_image, display_images\n","from of_comp.code.display_of import flow_with_legend"]},{"cell_type":"markdown","metadata":{"id":"HE11oQqCNq2k"},"source":["Download models for RAFT:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRGMSBH47hps","vscode":{"languageId":"python"}},"outputs":[],"source":["%cd RAFT\n","!./download_models.sh"]},{"cell_type":"markdown","metadata":{"id":"UobaFlG5Tfor"},"source":["Import the RAFT packages:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXGrcbVHNnUX","vscode":{"languageId":"python"}},"outputs":[],"source":["%cd /content/RAFT\n","sys.path.append('core')\n","from raft import RAFT\n","from utils.utils import InputPadder\n","from utils import flow_viz"]},{"cell_type":"markdown","metadata":{"id":"XFvRoCxIN-y1"},"source":["Several helper functions for RAFT:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5lUeRpfW83o8","vscode":{"languageId":"python"}},"outputs":[],"source":["def frame_preprocess(frame, device):\n","    frame = torch.from_numpy(frame).permute(2, 0, 1).float()\n","    frame = frame.unsqueeze(0)\n","    frame = frame.to(device)\n","    return frame\n","\n","def load_image(imfile):\n","    img = np.array(Image.open(imfile)).astype(np.uint8)\n","    img = torch.from_numpy(img).permute(2, 0, 1).float()\n","    return img[None].to(DEVICE)\n","\n","def get_cpu_model(model):\n","    new_model = OrderedDict()\n","    # get all layer's names from model\n","    for name in model:\n","        # create new name and update new model\n","        new_name = name[7:]\n","        new_model[new_name] = model[name]\n","    return new_model"]},{"cell_type":"markdown","metadata":{"id":"HYGFKjOVPBbc"},"source":["Parse some options for RAFT:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UV-qa1UzGDYu","vscode":{"languageId":"python"}},"outputs":[],"source":["from argparse import ArgumentParser\n","\n","DEVICE = \"cuda\"\n","\n","parser = ArgumentParser()\n","parser.add_argument(\"--model\", help=\"restore checkpoint\")\n","parser.add_argument(\"--iters\", type=int, default=12)\n","#parser.add_argument(\"--video\", type=str, default=\"./videos/car.mp4\")\n","parser.add_argument(\"--save\", action=\"store_true\", help=\"save demo frames\")\n","parser.add_argument(\"--small\", action=\"store_true\", help=\"use small model\")\n","parser.add_argument(\"--mixed_precision\", action=\"store_true\", help=\"use mixed precision\")\n","\n","#args = parser.parse_args(['--model', './models/raft-things.pth', '--video', '../crowd.mp4', '--iters', '12',  '--save'])\n","args = parser.parse_args(['--model', './models/raft-kitti.pth', '--iters', '12',  '--save'])"]},{"cell_type":"markdown","metadata":{"id":"dZKD79qwPGle"},"source":["Define a function for computing the optical flow on two images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wF9Ja9uDaO2","vscode":{"languageId":"python"}},"outputs":[],"source":["def inference(ima1_name, ima2_name, args):\n","    # get the RAFT model\n","    model = RAFT(args)\n","    # load pretrained weights\n","    pretrained_weights = torch.load(args.model)\n","\n","    save = args.save\n","    if save:\n","        if not os.path.exists(\"demo_frames\"):\n","            os.mkdir(\"demo_frames\")\n","\n","    if torch.cuda.is_available():\n","        device = \"cuda\"\n","        # parallel between available GPUs\n","        model = torch.nn.DataParallel(model)\n","        # load the pretrained weights into model\n","        model.load_state_dict(pretrained_weights)\n","        model.to(device)\n","    else:\n","        device = \"cpu\"\n","        # change key names for CPU runtime\n","        pretrained_weights = get_cpu_model(pretrained_weights)\n","        # load the pretrained weights into model\n","        model.load_state_dict(pretrained_weights)\n","\n","    # change model's mode to evaluation\n","    model.eval()\n","    with torch.no_grad():\n","\n","        image1 = load_image(ima1_name)\n","        image2 = load_image(ima2_name)\n","\n","        s = time.time()\n","        padder = InputPadder(image1.shape)\n","        image1, image2 = padder.pad(image1, image2)\n","\n","        flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n","        e = time.time()\n","\n","        of = flow_up.detach().cpu().numpy()\n","        of = np.transpose(of,axes=(2,3,1,0))[:,:,:,0]\n","\n","    return (of, e-s, flow_up)\n"]},{"cell_type":"markdown","metadata":{"id":"mkBtamWWUbsL"},"source":["Compute the optical flow on a pair of images:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXyZD3HgbGPS","vscode":{"languageId":"python"}},"outputs":[],"source":["from apng import APNG                        # To create animated png's\n","from IPython.display import Image as IImage  # To display images in Colab\n","\n","#image1_name = '/content/of_comp/images/vid_000340.png'\n","#image2_name = '/content/of_comp/images/vid_000341.png'\n","image1_name = '/content/of_comp/images/cd_000042.png'\n","image2_name = '/content/of_comp/images/cd_000046.png'\n","\n","import cv2\n","ima1  = cv2.imread(image1_name)\n","ima2  = cv2.imread(image2_name)\n","\n","ima1g = cv2.cvtColor(ima1, cv2.COLOR_BGR2GRAY)\n","ima2g = cv2.cvtColor(ima2, cv2.COLOR_BGR2GRAY)\n","\n","\n","APNG.from_files([image1_name, image2_name], delay=800).save(\"/content/result.png\")\n","IImage('/content/result.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUhfJmnbIe1w","vscode":{"languageId":"python"}},"outputs":[],"source":["%cd /content/RAFT\n","of_raft, tt, flow_up = inference(image1_name, image2_name, args)\n","print('Time Taken: {:.2f} seconds for image of size ({},{},{})'.format(tt, ima1.shape[0], ima1.shape[1], ima1.shape[2]))\n","\n","flow_with_legend(of_raft)"]},{"cell_type":"markdown","metadata":{"id":"ZKjCOBxQUk7B"},"source":["Compute the optical flow witht he Horn-Schunck method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cNzr8MCcPys1","vscode":{"languageId":"python"}},"outputs":[],"source":["s = time.time()\n","U, V = HornSchunck(ima1g, ima2g, alpha=1.0, Niter=100)\n","e = time.time()\n","print('Time Taken: {:.2f} seconds for image of size ({},{},{})'.format(e - s, ima1.shape[0], ima1.shape[1], ima1.shape[2]))\n","\n","of_hs = np.stack([U,V], axis=2)\n","flow_with_legend (of_hs)"]},{"cell_type":"markdown","metadata":{"id":"6fVA9PQsUs1y"},"source":["Compute optical flow with the [Farneback](http://www.diva-portal.org/smash/get/diva2:273847/FULLTEXT01.pdf) method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJDfmPAPP-vY","vscode":{"languageId":"python"}},"outputs":[],"source":["s = time.time()\n","of_fb = cv2.calcOpticalFlowFarneback(ima1g,ima2g, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","e = time.time()\n","print('Time Taken: {:.2f} seconds for image of size ({},{},{})'.format(e - s, ima1.shape[0], ima1.shape[1], ima1.shape[2]))\n","flow_with_legend (of_fb)"]},{"cell_type":"markdown","metadata":{"id":"tAbTCzE9baxJ"},"source":["Compute optical flow with the Brox method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ke0kbDWTbXFA","vscode":{"languageId":"python"}},"outputs":[],"source":["# Flow Options:\n","alpha = 0.012\n","ratio = 0.75\n","minWidth = 20\n","nOuterFPIterations = 7\n","nInnerFPIterations = 1\n","nSORIterations = 30\n","colType = 0  # 0 or default:RGB, 1:GRAY (but pass gray image with shape (h,w,1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRDUf2HRbd0o","vscode":{"languageId":"python"}},"outputs":[],"source":["%cd /content/pyflow\n","import pyflow\n","import time\n","import numpy as np\n","\n","s = time.time()\n","u, v, im2W = pyflow.coarse2fine_flow(\n","    ima1.astype(float)/255, ima2.astype(float)/255, alpha, ratio, minWidth, nOuterFPIterations, nInnerFPIterations,\n","    nSORIterations, colType)\n","of_brox = np.stack([u,v], axis=2)\n","e = time.time()\n","print('Time Taken: {:.2f} seconds for image of size ({},{},{})'.format(e - s, ima1.shape[0], ima1.shape[1], ima1.shape[2]))\n","flow_with_legend (of_brox)"]},{"cell_type":"markdown","metadata":{"id":"54vbR66fU1rg"},"source":["Let's compute the DFD error:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vZogA3KHQqd","vscode":{"languageId":"python"}},"outputs":[],"source":["# https://github.com/opencv/opencv/blob/master/samples/python/opt_flow.py\n","def warp_flow(img, flow):\n","    h, w = img.shape[:2]\n","    flow = -flow\n","    flow[:,:,0] += np.arange(w)\n","    flow[:,:,1] += np.arange(h)[:,np.newaxis]\n","\n","    compensated_ima = cv2.remap(img, flow, None, cv2.INTER_LINEAR)\n","    return compensated_ima\n","\n","def DFD_flow(ima1, ima2, flow):\n","    '''\n","    Compute the Displaced Frame Difference between I2(t) and I1(t-1) as:\n","    I2(r,t) - I1(r-D(r), t-1)\n","    where D(r) is the optical flow\n","    '''\n","    ima1_comp = warp_flow(ima1, flow)\n","    #ima1_comp = warp_back(ima1, flow[:,:,0], flow[:,:,1])\n","    dfd   = ima2 - ima1_comp\n","    dfd_e = np.sqrt(np.sum(dfd*dfd)) / np.prod(ima1.shape[0:2])\n","\n","    return dfd, dfd_e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lt0q9AsbHRko","vscode":{"languageId":"python"}},"outputs":[],"source":["#DFD_br,   err_br   = DFD_flow(ima1g.astype(np.float32), ima2g.astype(np.float32), of_brox.astype(np.float32))\n","#print ('Brox 2004    DFD square error: {}'.format(err_br))\n","#norm_DFD_brox = (((DFD_br   - np.min(DFD_br))  / 510) * 255).astype(np.uint8)\n","#display_image (norm_DFD_brox, 'DFD Brox 2004', size=1.0)\n","\n","\n","of_null = np.zeros_like(of_raft)  # No optical flow \n","\n","FD, err_nc         = DFD_flow(ima1g.astype(np.float32), ima2g.astype(np.float32), of_null)\n","DFD_raft, err_raft = DFD_flow(ima1g.astype(np.float32), ima2g.astype(np.float32), of_raft)\n","DFD_hs,   err_hs   = DFD_flow(ima1g.astype(np.float32), ima2g.astype(np.float32), of_hs.astype(np.float32))\n","DFD_fb,   err_fb   = DFD_flow(ima1g.astype(np.float32), ima2g.astype(np.float32), of_fb)\n","DFD_br,   err_br   = DFD_flow(ima1g.astype(np.float32), ima2g.astype(np.float32), of_brox.astype(np.float32))\n","\n","print ('------------  FD square error: {}'.format(err_nc))\n","print ('RAFT         DFD square error: {}'.format(err_raft))\n","print ('Horn-Schunck DFD square error: {}'.format(err_hs))\n","print ('Brox 2004    DFD square error: {}'.format(err_br))\n","print ('Farneback    DFD square error: {}'.format(err_fb))\n","\n","norm_FD_null  = (((FD - np.min(FD))/ 510) * 255).astype(np.uint8)\n","norm_DFD_raft = (((DFD_raft - np.min(DFD_raft))/ 510) * 255).astype(np.uint8)\n","norm_DFD_hs   = (((DFD_hs   - np.min(DFD_hs))  / 510) * 255).astype(np.uint8)\n","norm_DFD_brox = (((DFD_br   - np.min(DFD_br))  / 510) * 255).astype(np.uint8)\n","norm_DFD_fb   = (((DFD_fb   - np.min(DFD_fb))  / 510) * 255).astype(np.uint8)\n","\n","display_image (norm_FD_null,  'Frame Difference', size=1.0)\n","display_image (norm_DFD_raft, 'DFD RAFT', size=1.0)\n","display_image (norm_DFD_hs,   'DFD Horn-Schunck', size=1.0)\n","display_image (norm_DFD_brox, 'DFD Brox 2004', size=1.0)\n","display_image (norm_DFD_fb,   'DFD Farneback', size=1.0)\n"]},{"cell_type":"markdown","metadata":{"id":"iuPSKWgIZ3O9"},"source":["Let's simulate a camera movement two pixels to the right.\n","The motion vectors should be all $u = -2, v = 0$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeVfMQI1ZNKt","vscode":{"languageId":"python"}},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","# Check\n","%cd /content\n","ima_ori = cv2.imread(image1_name)\n","dx = -2\n","dy = -0\n","\n","h,w = ima_ori.shape[0:2]\n","\n","# Create a pair of images simulating camera translational motion\n","ima1 = ima_ori[0:h-np.abs(dy), 0:w-np.abs(dx),:]\n","ima2 = ima_ori[np.abs(dy):,    np.abs(dx):   ,:]\n","\n","# Add 1 pixel at the right\n","ima1 = cv2.copyMakeBorder(ima1,np.abs(dy),0,0,np.abs(dx),cv2.BORDER_REPLICATE)\n","ima2 = cv2.copyMakeBorder(ima2,np.abs(dy),0,0,np.abs(dx),cv2.BORDER_REPLICATE)\n","\n","\n","image1_name = '/content/cairo1_prev.png'\n","image2_name = '/content/cairo1_curr.png'\n","cv2.imwrite(image1_name, ima1)\n","cv2.imwrite(image2_name, ima2)\n","\n","\n","ima1g = cv2.cvtColor(ima1, cv2.COLOR_BGR2GRAY)\n","ima2g = cv2.cvtColor(ima2, cv2.COLOR_BGR2GRAY)\n","\n","#ima1 = ima2.astype(np.float32)\n","#ima2 = ima2.astype(np.float32)\n","\n","# Let's create the Ground Truth optical flow\n","gt_flow = np.stack([np.ones_like(ima1g)*dx, np.ones_like(ima2g)*dy], axis=2)"]},{"cell_type":"markdown","metadata":{"id":"l5s70-S7aAUc"},"source":["Now, compute optical flow with all the previous methods:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1Zer6qJZ_TL","vscode":{"languageId":"python"}},"outputs":[],"source":["# RAFT\n","%cd /content/RAFT\n","of_raft, tt, flow_up = inference(image1_name, image2_name, args) \n","\n","# Horn-Schunck\n","U, V = HornSchunck(ima1g, ima2g, alpha=1.0, Niter=100)\n","of_hs = np.stack([U,V], axis=2)\n","\n","# Farneback\n","of_fb = cv2.calcOpticalFlowFarneback(ima1g,ima2g, None, 0.5, 3, 15, 3, 5, 1.2, 0) # Farneback\n","\n","# Brox\n","%cd /content/pyflow\n","import pyflow\n","u, v, im2W = pyflow.coarse2fine_flow(\n","    ima1.astype(float)/255, ima2.astype(float)/255, alpha, ratio, minWidth, nOuterFPIterations, nInnerFPIterations,\n","    nSORIterations, colType)\n","of_brox = np.stack([u,v], axis=2)"]},{"cell_type":"markdown","metadata":{"id":"L8OTvjUQX5g9"},"source":["Now, lets compute the average End Point Error metric:\n","$EPE = \\|V_{gt} - V_{calc}\\| = \\sqrt{(\\Delta x_{gt}-\\Delta x_{calc})^2 + (\\Delta y_{gt} - \\Delta y_{calc})^2}$. This measures the 'correctness' of the motion vectors. Note that some methods (RAFT) are optimized for this criterion.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wM-_hzLYWP8J","vscode":{"languageId":"python"}},"outputs":[],"source":["import numpy as np\n","def EPE (gt_flow, hypo_flow):\n","  sqerr = (gt_flow-hypo_flow)**2\n","  return np.sum(np.sqrt(sqerr[0]+sqerr[1])) / gt_flow[0].size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VbF6J3Ua4AH","vscode":{"languageId":"python"}},"outputs":[],"source":["epe_raft = EPE(gt_flow, of_raft)\n","\n","epe_hs   = EPE(gt_flow, of_hs)\n","\n","epe_fb   = EPE(gt_flow, of_fb)\n","\n","%cd /content/pyflow\n","epe_brox = EPE(gt_flow, of_brox)\n","\n","print ('EPE RAFT:         {}'.format(epe_raft))\n","print ('EPE Horn-Schunck: {}'.format(epe_hs))\n","print ('EPE Farneback:    {}'.format(epe_fb))\n","print ('EPE Brox:         {}'.format(epe_brox))"]},{"cell_type":"markdown","metadata":{"id":"lDuirfMLptjj"},"source":["Cumpute the DFD:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EfrMllvtenk8","vscode":{"languageId":"python"}},"outputs":[],"source":["DFD_raft, err_raft = DFD_flow(ima1.astype(np.float32), ima2.astype(np.float32), of_raft)\n","DFD_hs,   err_hs   = DFD_flow(ima1.astype(np.float32), ima2.astype(np.float32), of_hs.astype(np.float32))\n","DFD_fb,   err_fb   = DFD_flow(ima1.astype(np.float32), ima2.astype(np.float32), of_fb)\n","DFD_br,   err_br   = DFD_flow(ima1.astype(np.float32), ima2.astype(np.float32), of_brox.astype(np.float32))\n","\n","print ('RAFT         DFD square error: {}'.format(err_raft))\n","print ('Horn-Schunck DFD square error: {}'.format(err_hs))\n","print ('Farneback    DFD square error: {}'.format(err_fb))\n","print ('Brox 2004    DFD square error: {}'.format(err_br))\n"]},{"cell_type":"markdown","metadata":{"id":"NA8sFGFodS81"},"source":["In this case, where the motion is the same for all pixels and the displacement is small, the Farneback method provides a good compensated image."]},{"cell_type":"markdown","metadata":{"id":"YLFL3KFKbHGR"},"source":["## Comparison on SINTEL\n","\n","[SINTEL](http://sintel.is.tue.mpg.de/) is a data set for the evaluation of optical flow derived from the open source 3D animated short film, Sintel. The key features are: very long sequences, large motions, specular reflections, motion blur, defocus blur and atmospheric effects.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yf6oNo1wb9G2","vscode":{"languageId":"python"}},"outputs":[],"source":["import numpy as np\n","import os\n","import sys\n","\n","# Adapted from: https://stackoverflow.com/questions/28013200/reading-middlebury-flow-files-with-python-bytes-array-numpy\n","def read_flo(of_file_name):\n","    # WARNING: this will work on little-endian architectures (eg Intel x86) only!\n","    data2D = None\n","    ok     = False\n","    with open(of_file_name, 'rb') as f:\n","        magic = np.fromfile(f, np.float32, count=1)\n","        if 202021.25 != magic:\n","            print('Magic number incorrect. Invalid .flo file')\n","        else:\n","            w = np.fromfile(f, np.int32, count=1)[0]\n","            h = np.fromfile(f, np.int32, count=1)[0]\n","            print('Reading %d x %d flo file' % (w, h))\n","            data = np.fromfile(f, np.float32, count=2*w*h)\n","            # Reshape data into 3D array (columns, rows, bands)\n","            data2D = np.resize(data, (h, w, 2))\n","            ok = True\n","    return data2D, ok"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52FVj7LgcMUk","vscode":{"languageId":"python"}},"outputs":[],"source":["# RAFT\n","%cd /content/RAFT\n","of_raft, tt, flow_up = inference(image1_name, image2_name, args) \n","\n","# Horn-Schunck\n","U, V = HornSchunck(ima1g, ima2g, alpha=1.0, Niter=100)\n","of_hs = np.stack([U,V], axis=2)\n","\n","# Farneback\n","of_fb = cv2.calcOpticalFlowFarneback(ima1g,ima2g, None, 0.5, 3, 15, 3, 5, 1.2, 0) # Farneback\n","\n","# Brox\n","%cd /content/pyflow\n","import pyflow\n","u, v, im2W = pyflow.coarse2fine_flow(\n","    ima1.astype(float)/255, ima2.astype(float)/255, alpha, ratio, minWidth, nOuterFPIterations, nInnerFPIterations,\n","    nSORIterations, colType)\n","of_brox = np.stack([u,v], axis=2)"]},{"cell_type":"markdown","metadata":{"id":"YPrB73OckVUJ"},"source":["## Conclusions:\n","\n","Depending of the type of motion and the type of metric, the methods behave differently. For instance, RAFT is optimized for EPE metric (the loss function is similar to EPE) and obtains better result for this metric. For simple motions, all methods work quite well. For complex motion (try computing optical flow between cd_000042.png and cd_000046.png), RAFT is slightly better but, for simpler motions, Farneback gives excellent results. Brox is also very good but takes a long time unless you use a GPU implementation (the one used here does not).\n","\n","For image compensation, if your motion is not highly complex, classical methods are still an interesting choice.\n","\n","For motion segmentation or action recognition, Brox and RAFT are good candidates as they capture better the transitions between the motion of different objects. "]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNPHTaJl1J2/rM8sNSKhpHp","collapsed_sections":[],"name":"OpticalFlowComparison.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
